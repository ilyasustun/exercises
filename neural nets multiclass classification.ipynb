{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ilyas Ustun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Multiclass Classification Exercise\n",
    "\n",
    "## Objective\n",
    "In this exercise, you will build and train a neural network to classify wine types using the Wine dataset. You'll learn how to:\n",
    "\n",
    "1. Load and explore classification data\n",
    "2. Prepare data for neural network classification\n",
    "3. Build a neural network for multiclass classification\n",
    "4. Train and evaluate the classification model\n",
    "5. Visualize classification results and performance metrics\n",
    "\n",
    "## Dataset\n",
    "We'll use the Wine dataset from sklearn, which contains chemical analysis of wines from three different cultivars. Our goal is to classify wines into one of three classes based on 13 chemical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for this classification exercise.\n",
    "\n",
    "**Hints:**\n",
    "- You'll need TensorFlow for neural networks\n",
    "- Import numpy, matplotlib, seaborn, and pandas for data handling and visualization\n",
    "- From sklearn, import: datasets, model_selection, preprocessing, metrics, and utils.class_weight\n",
    "- Set a plotting style for better visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import all required libraries\n",
    "# Your code here\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Load and Explore the Dataset\n",
    "\n",
    "Load the Wine dataset and explore its structure.\n",
    "\n",
    "**Hints:**\n",
    "- Use `load_wine()` from sklearn.datasets\n",
    "- Check the shape of features and targets\n",
    "- Examine feature names and target names\n",
    "- Look at the dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the Wine dataset\n",
    "# Your code here\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "# TODO: Print dataset shape, feature names, target names, etc.\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a DataFrame for easier exploration\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "# TODO: Display basic statistics\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "# TODO: Check and display class distribution\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations for data exploration\n",
    "# Hints:\n",
    "# - Create a 2x2 subplot\n",
    "# - Plot class distribution as a bar chart\n",
    "# - Create a correlation heatmap for top features\n",
    "# - Make a scatter plot of two important features colored by class\n",
    "# - Create a box plot showing feature distribution by class\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Prepare the Data\n",
    "\n",
    "Split and prepare the data for neural network training.\n",
    "\n",
    "**Hints:**\n",
    "- Split into train (70%), validation (15%), and test (15%) sets\n",
    "- Use `stratify` parameter to maintain class distribution\n",
    "- Normalize features using StandardScaler\n",
    "- Convert labels to categorical format (one-hot encoding)\n",
    "- Calculate class weights for handling imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into train, validation, and test sets\n",
    "# Hints:\n",
    "# - Use train_test_split twice\n",
    "# - First split: 85% temp, 15% test\n",
    "# - Second split: 70% train, 15% validation (from temp)\n",
    "# - Use stratify parameter and random_state=42\n",
    "\n",
    "# Your code here\n",
    "\n",
    "print(\"Data split completed:\")\n",
    "# TODO: Print the size of each split\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize features using StandardScaler\n",
    "# Hints:\n",
    "# - Fit the scaler on training data only\n",
    "# - Transform all three sets (train, validation, test)\n",
    "# - Check that mean is ~0 and std is ~1 after normalization\n",
    "\n",
    "# Your code here\n",
    "\n",
    "print(\"Data normalization completed:\")\n",
    "# TODO: Print shapes and verify normalization\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert labels to categorical (one-hot encoding)\n",
    "# Hints:\n",
    "# - Use tf.keras.utils.to_categorical()\n",
    "# - Convert all three label sets\n",
    "# - Check the number of classes\n",
    "\n",
    "# Your code here\n",
    "\n",
    "print(\"Label encoding completed:\")\n",
    "# TODO: Print shapes and show example of one-hot encoding\n",
    "# Your code here\n",
    "\n",
    "# TODO: Calculate class weights for handling imbalance\n",
    "# Hint: Use compute_class_weight with 'balanced' mode\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Build a Neural Network for Classification\n",
    "\n",
    "Create a Sequential model for multiclass classification.\n",
    "\n",
    "**Hints:**\n",
    "- Use Sequential model with Dense layers\n",
    "- Start with 64 neurons in first hidden layer\n",
    "- Add more hidden layers with decreasing neurons (32, 16)\n",
    "- Use ReLU activation for hidden layers\n",
    "- Output layer should have 3 neurons (number of classes)\n",
    "- Use softmax activation for output layer (multiclass classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a Sequential model for classification\n",
    "# Architecture suggestion:\n",
    "# - Input layer: 13 features\n",
    "# - Hidden layer 1: 64 neurons, ReLU\n",
    "# - Hidden layer 2: 32 neurons, ReLU\n",
    "# - Hidden layer 3: 16 neurons, ReLU\n",
    "# - Output layer: 3 neurons, softmax\n",
    "\n",
    "# Your code here\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "# TODO: Display model summary\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Compile the Model\n",
    "\n",
    "Configure the model for training with appropriate loss function and metrics.\n",
    "\n",
    "**Hints:**\n",
    "- Use 'adam' optimizer\n",
    "- For multiclass classification, use 'categorical_crossentropy' loss\n",
    "- Track 'accuracy' as a metric\n",
    "- Remember: this is different from regression (MSE loss, MAE metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile the model\n",
    "# Your code here\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nConfiguration:\")\n",
    "print(\"- Optimizer: Adam\")\n",
    "print(\"- Loss: Categorical Crossentropy\")\n",
    "print(\"- Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Train the Model\n",
    "\n",
    "Train the neural network on the prepared data.\n",
    "\n",
    "**Hints:**\n",
    "- Use 150 epochs\n",
    "- Set batch_size=16 (small dataset)\n",
    "- Include validation_data parameter\n",
    "- Use the class_weight dictionary you calculated\n",
    "- Set verbose=1 to see training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "# TODO: Print final training and validation accuracy\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Visualize Training Progress\n",
    "\n",
    "Create plots to visualize the training process.\n",
    "\n",
    "**Hints:**\n",
    "- Create 1x2 subplots\n",
    "- Plot training and validation loss over epochs\n",
    "- Plot training and validation accuracy over epochs\n",
    "- Add labels, legends, and grid\n",
    "- Look for signs of overfitting (gap between train and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training history\n",
    "# Your code here\n",
    "\n",
    "# TODO: Analyze training results\n",
    "# Calculate and print final metrics and overfitting indicators\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Test the Model\n",
    "\n",
    "Evaluate the model on the test set and analyze predictions.\n",
    "\n",
    "**Hints:**\n",
    "- Use model.evaluate() to get test loss and accuracy\n",
    "- Use model.predict() to get prediction probabilities\n",
    "- Convert probabilities to class predictions using np.argmax()\n",
    "- Generate a classification report\n",
    "- Show some example predictions with confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate model on test set\n",
    "# Your code here\n",
    "\n",
    "# TODO: Make predictions and convert to class labels\n",
    "# Your code here\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "# TODO: Print test loss and accuracy\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate and print detailed classification report\n",
    "# Your code here\n",
    "\n",
    "print(\"\\nFirst 15 Predictions with Confidence:\")\n",
    "# TODO: Show first 15 predictions with confidence scores\n",
    "# Format: Predicted | Actual | Confidence | Correct\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Visualize Classification Results\n",
    "\n",
    "Create comprehensive visualizations to understand model performance.\n",
    "\n",
    "**Hints:**\n",
    "- Create a 2x2 subplot layout\n",
    "- Plot 1: Confusion matrix as heatmap\n",
    "- Plot 2: Classification metrics (precision, recall, F1) by class\n",
    "- Plot 3: Distribution of prediction confidence scores\n",
    "- Plot 4: Compare confidence for correct vs incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create comprehensive visualization\n",
    "# Your code here\n",
    "\n",
    "# TODO: Print performance summary\n",
    "# Include test accuracy, average confidence, etc.\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Analyze Model Predictions\n",
    "\n",
    "Analyze which samples the model finds most difficult to classify.\n",
    "\n",
    "**Hints:**\n",
    "- Find samples with lowest confidence scores\n",
    "- Use np.argsort() to sort by confidence\n",
    "- Show the most uncertain predictions\n",
    "- Calculate class-wise accuracy and confidence\n",
    "- Look for patterns in difficult samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze difficult predictions (lowest confidence)\n",
    "# Your code here\n",
    "\n",
    "# TODO: Analyze class-wise performance\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Improved Model with Regularization\n",
    "\n",
    "Try to improve the model using regularization techniques.\n",
    "\n",
    "**Hints:**\n",
    "- Add Dropout layers (0.3 dropout rate)\n",
    "- Add BatchNormalization layers\n",
    "- Use more neurons in hidden layers (128, 64, 32)\n",
    "- Set up EarlyStopping callback\n",
    "- Use ReduceLROnPlateau callback\n",
    "- Compare performance with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build improved model with regularization\n",
    "# Your code here\n",
    "\n",
    "print(\"Building improved model with regularization...\")\n",
    "# TODO: Display model summary\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up callbacks for improved training\n",
    "# Your code here\n",
    "\n",
    "# TODO: Train improved model\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate improved model and compare with original\n",
    "# Your code here\n",
    "\n",
    "# TODO: Print detailed comparison\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare training histories of both models\n",
    "# Create plots showing loss and accuracy comparison\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Questions - Test Your Understanding\n",
    "\n",
    "Answer these questions to check your understanding:\n",
    "\n",
    "### 1. What does the softmax activation function do in the output layer?\n",
    "**Your answer:** _Write your answer here_\n",
    "\n",
    "### 2. Why do we use categorical crossentropy instead of mean squared error for classification?\n",
    "**Your answer:** _Write your answer here_\n",
    "\n",
    "### 3. What does a confusion matrix tell us about our model's performance?\n",
    "**Your answer:** _Write your answer here_\n",
    "\n",
    "### 4. What is the difference between precision and recall?\n",
    "**Your answer:** _Write your answer here_\n",
    "\n",
    "### 5. How do dropout and batch normalization help improve model performance?\n",
    "**Your answer:** _Write your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Feature Importance Analysis\n",
    "\n",
    "Analyze which features contribute most to the model's predictions.\n",
    "\n",
    "**Hints:**\n",
    "- Extract weights from the first layer using model.layers[0].get_weights()[0]\n",
    "- Calculate feature importance as sum of absolute weights\n",
    "- Create a horizontal bar plot showing feature importance\n",
    "- Identify the most and least important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze feature importance\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "🎯 **Main Learning Points:**\n",
    "\n",
    "1. **Classification vs Regression**: Different output layers, loss functions, and metrics\n",
    "2. **Data preparation**: Stratified splits, normalization, one-hot encoding\n",
    "3. **Evaluation metrics**: Accuracy, precision, recall, F1-score, confusion matrices\n",
    "4. **Regularization**: Dropout, batch normalization, early stopping\n",
    "5. **Visualization**: Training curves, confusion matrices, confidence distributions\n",
    "6. **Class imbalance**: Using class weights\n",
    "7. **Model comparison**: Systematic evaluation of improvements\n",
    "\n",
    "**Next Steps:**\n",
    "- Try different datasets (Iris, Digits, etc.)\n",
    "- Experiment with different architectures\n",
    "- Explore advanced techniques (ensemble methods, transfer learning)\n",
    "- Practice with real-world datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
