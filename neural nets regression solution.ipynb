{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ilyas Ustun  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Regression Exercise Solutions\n",
    "\n",
    "## Objective\n",
    "In this exercise, you will build and train a simple neural network to predict house prices using the California Housing dataset. You'll learn how to:\n",
    "\n",
    "1. Load and explore data\n",
    "2. Prepare data for neural networks\n",
    "3. Build a simple neural network for regression\n",
    "4. Train and evaluate the model\n",
    "5. Visualize results\n",
    "\n",
    "## Dataset\n",
    "We'll use the California Housing dataset from sklearn, which contains information about housing districts in California. Our goal is to predict the median house value based on features like location, population, and income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Import Required Libraries\n",
    "\n",
    "**Solution Explanation:**\n",
    "We import all necessary libraries for data handling, model building, and visualization. Each library serves a specific purpose:\n",
    "- `tensorflow`: For building and training neural networks\n",
    "- `numpy`: For numerical operations\n",
    "- `matplotlib`: For creating visualizations\n",
    "- `sklearn`: For dataset loading, preprocessing, and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Load and Explore the Dataset\n",
    "\n",
    "**Solution Explanation:**\n",
    "We load the California Housing dataset and explore its structure to understand what we're working with. This includes checking the shape of data, feature names, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {housing.feature_names}\")\n",
    "print(f\"Target description: {housing.target_names}\")\n",
    "print(f\"Dataset description: {housing.DESCR[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(f\"House prices - Mean: ${np.mean(y):.2f}, Std: ${np.std(y):.2f}\")\n",
    "print(f\"Price range: ${np.min(y):.2f} - ${np.max(y):.2f}\")\n",
    "print(f\"Number of samples: {len(y)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of house prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('House Price (in hundreds of thousands)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of House Prices in California Housing Dataset')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"The distribution shows that most houses are priced between $1-3 hundred thousand.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Prepare the Data\n",
    "\n",
    "**Solution Explanation:**\n",
    "Data preparation is crucial for neural networks. We:\n",
    "1. Split data into training (80%) and testing (20%) sets\n",
    "2. Normalize features using StandardScaler to ensure all features have similar scales\n",
    "3. Normalization helps the neural network converge faster and prevents features with larger values from dominating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split completed:\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features using StandardScaler\n",
    "# This is crucial for neural networks as it helps with convergence\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_test_scaled = scaler.transform(X_test)        # Transform test data using same scaler\n",
    "\n",
    "print(\"Data normalization completed:\")\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"Training targets shape: {y_train.shape}\")\n",
    "print(f\"Test targets shape: {y_test.shape}\")\n",
    "\n",
    "# Verify normalization (should be close to 0 mean, 1 std)\n",
    "print(f\"\\nAfter normalization - Training data mean: {np.mean(X_train_scaled):.6f}\")\n",
    "print(f\"After normalization - Training data std: {np.std(X_train_scaled):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Build a Simple Neural Network\n",
    "\n",
    "**Solution Explanation:**\n",
    "We create a Sequential model with:\n",
    "- Input layer: 8 features (housing characteristics)\n",
    "- Hidden layer 1: 50 neurons with ReLU activation\n",
    "- Hidden layer 2: 25 neurons with ReLU activation\n",
    "- Output layer: 1 neuron (house price prediction) with no activation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential model with 2 hidden layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output layer for regression (no activation)\n",
    "])\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"- Input layer: 8 features (housing characteristics)\")\n",
    "print(\"- Hidden layer 1: 50 neurons with ReLU activation\")\n",
    "print(\"- Hidden layer 2: 25 neurons with ReLU activation\")\n",
    "print(\"- Output layer: 1 neuron (house price prediction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Compile the Model\n",
    "\n",
    "**Solution Explanation:**\n",
    "Model compilation configures the training process:\n",
    "- **Optimizer**: Adam (adaptive learning rate, works well for most problems)\n",
    "- **Loss function**: Mean Squared Error (MSE) - standard for regression\n",
    "- **Metrics**: Mean Absolute Error (MAE) - easier to interpret than MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training\n",
    "model.compile(\n",
    "    optimizer='adam',                    # Adaptive learning rate optimizer\n",
    "    loss='mean_squared_error',          # MSE for regression\n",
    "    metrics=['mean_absolute_error']     # MAE for easier interpretation\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(\"\\nCompilation settings:\")\n",
    "print(\"- Optimizer: Adam (adaptive learning rate)\")\n",
    "print(\"- Loss function: Mean Squared Error (MSE)\")\n",
    "print(\"- Metrics: Mean Absolute Error (MAE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Train the Model\n",
    "\n",
    "**Solution Explanation:**\n",
    "Training parameters:\n",
    "- **Epochs**: 100 (number of complete passes through the training data)\n",
    "- **Batch size**: 32 (number of samples processed before updating weights)\n",
    "- **Validation split**: 0.2 (20% of training data used for validation)\n",
    "- **Verbose**: 1 (show training progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with validation split\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # Use 20% of training data for validation\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Visualize Training Progress\n",
    "\n",
    "**Solution Explanation:**\n",
    "Training visualization helps us understand:\n",
    "- **Loss curves**: How well the model is learning (decreasing loss is good)\n",
    "- **Validation vs Training**: Gap indicates overfitting if validation loss is much higher\n",
    "- **MAE curves**: Mean Absolute Error in actual units (hundreds of thousands of dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE', linewidth=2)\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Model MAE During Training')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training analysis:\")\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "print(f\"Final training loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final validation loss: {final_val_loss:.4f}\")\n",
    "print(f\"Overfitting indicator: {(final_val_loss - final_train_loss) / final_train_loss * 100:.1f}% higher validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Test the Model\n",
    "\n",
    "**Solution Explanation:**\n",
    "Model evaluation on unseen test data gives us the true performance:\n",
    "- **Test Loss (MSE)**: Average squared error\n",
    "- **Test MAE**: Average absolute error in hundreds of thousands of dollars\n",
    "- **Individual predictions**: Examples of how well the model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Results:\")\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"On average, our predictions are off by ${test_mae:.2f} hundred thousand\")\n",
    "print(f\"Root Mean Squared Error: ${np.sqrt(test_loss):.4f} hundred thousand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Show first 10 predictions vs actual values\n",
    "print(\"First 10 Predictions vs Actual Values:\")\n",
    "print(\"Predicted | Actual | Error\")\n",
    "print(\"-\" * 30)\n",
    "for i in range(10):\n",
    "    error = abs(predictions[i][0] - y_test[i])\n",
    "    print(f\"{predictions[i][0]:8.2f} | {y_test[i]:6.2f} | {error:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Visualize Results\n",
    "\n",
    "**Solution Explanation:**\n",
    "Result visualization helps us understand model performance:\n",
    "- **Scatter plot**: Points close to diagonal line indicate good predictions\n",
    "- **RÂ² score**: Coefficient of determination (closer to 1.0 is better)\n",
    "- **Error distribution**: Shows if errors are normally distributed around zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Scatter plot of actual vs predicted values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, predictions, alpha=0.5, color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual House Prices')\n",
    "plt.ylabel('Predicted House Prices')\n",
    "plt.title('Actual vs Predicted House Prices')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add RÂ² score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "plt.text(0.05, 0.95, f'RÂ² = {r2:.3f}', transform=plt.gca().transAxes, \n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Histogram of prediction errors\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_test - predictions.flatten()\n",
    "plt.hist(errors, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "plt.axvline(np.mean(errors), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(errors):.3f}')\n",
    "plt.axvline(np.median(errors), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(errors):.3f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model Performance Summary:\")\n",
    "print(f\"RÂ² Score: {r2:.3f} (explains {r2*100:.1f}% of variance)\")\n",
    "print(f\"Mean Error: {np.mean(errors):.3f} (should be close to 0)\")\n",
    "print(f\"Error Standard Deviation: {np.std(errors):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Improved Model\n",
    "\n",
    "**Solution Explanation:**\n",
    "Let's try to improve our model with:\n",
    "- **More neurons**: 100 â†’ 50 â†’ 25 architecture\n",
    "- **Dropout layers**: Prevent overfitting by randomly setting some neurons to zero\n",
    "- **Early stopping**: Stop training when validation loss stops improving\n",
    "- **Learning rate scheduling**: Adjust learning rate during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building improved model with regularization...\")\n",
    "\n",
    "# Try a deeper network with dropout for regularization\n",
    "improved_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),  # Dropout for regularization\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile with a specific learning rate\n",
    "improved_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Training improved model...\")\n",
    "improved_history = improved_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining stopped after {len(improved_history.history['loss'])} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate improved model\n",
    "improved_test_loss, improved_test_mae = improved_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "improved_predictions = improved_model.predict(X_test_scaled)\n",
    "improved_r2 = r2_score(y_test, improved_predictions)\n",
    "\n",
    "print(f\"Model Comparison:\")\n",
    "print(f\"Original Model  - Test MAE: {test_mae:.4f}, RÂ²: {r2:.4f}\")\n",
    "print(f\"Improved Model  - Test MAE: {improved_test_mae:.4f}, RÂ²: {improved_r2:.4f}\")\n",
    "print(f\"\\nImprovement: {((test_mae - improved_test_mae) / test_mae * 100):.1f}% reduction in MAE\")\n",
    "print(f\"RÂ² improvement: {((improved_r2 - r2) / r2 * 100):.1f}% increase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training histories\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['val_loss'], label='Original Model', linewidth=2)\n",
    "plt.plot(improved_history.history['val_loss'], label='Improved Model', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Model Comparison - Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Original Model', linewidth=2)\n",
    "plt.plot(improved_history.history['val_mean_absolute_error'], label='Improved Model', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.title('Model Comparison - Validation MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Questions - Answers\n",
    "\n",
    "Here are the answers to help check your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What does the loss function measure in regression?\n",
    "\n",
    "**Answer:** The loss function (MSE - Mean Squared Error) measures the average squared difference between predicted and actual values. It penalizes larger errors more heavily than smaller ones, which encourages the model to avoid making big mistakes.\n",
    "\n",
    "### 2. Why do we normalize the input features?\n",
    "\n",
    "**Answer:** Normalization ensures all features are on the same scale (mean=0, std=1), preventing features with larger numerical ranges from dominating the learning process. This helps the neural network converge faster and more reliably.\n",
    "\n",
    "### 3. What does it mean if the validation loss is much higher than training loss?\n",
    "\n",
    "**Answer:** This indicates **overfitting** - the model has memorized the training data but doesn't generalize well to new, unseen data. The model performs well on training data but poorly on validation/test data.\n",
    "\n",
    "### 4. How can you tell if your model is making good predictions from the scatter plot?\n",
    "\n",
    "**Answer:** Good predictions show points clustered close to the diagonal line (y=x) in the actual vs predicted scatter plot. The RÂ² score close to 1.0 also indicates good performance, meaning the model explains most of the variance in the data.\n",
    "\n",
    "### 5. What would you try next to improve your model's performance?\n",
    "\n",
    "**Answer:** Several strategies:\n",
    "- **Architecture**: Add more layers or neurons, try different activation functions\n",
    "- **Regularization**: Use dropout, L1/L2 regularization to prevent overfitting\n",
    "- **Training**: Adjust learning rate, use learning rate scheduling, train longer with early stopping\n",
    "- **Data**: Feature engineering, collect more data, handle outliers\n",
    "- **Ensemble**: Combine multiple models for better predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "ðŸŽ¯ **Main Learning Points:**\n",
    "\n",
    "1. **Data preprocessing is crucial** - Normalization helps neural networks converge faster and more reliably\n",
    "\n",
    "2. **Monitor training progress** - Use validation data to detect overfitting and guide training decisions\n",
    "\n",
    "3. **Multiple evaluation metrics** - MSE, MAE, and RÂ² provide different perspectives on model performance\n",
    "\n",
    "4. **Visualization is powerful** - Plots help understand model behavior and identify issues\n",
    "\n",
    "5. **Regularization helps** - Techniques like dropout and early stopping prevent overfitting\n",
    "\n",
    "6. **Experimentation is key** - Try different architectures, hyperparameters, and techniques to improve performance\n",
    "\n",
    "**ðŸŽ‰ Exercise completed successfully!** You now have a solid foundation in neural network regression using TensorFlow and Keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
